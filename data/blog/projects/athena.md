---
title: 'Афина - Поисковик Курсов со Всего Мира с 200,000+ Курсами'
date: '2022-02-16'
tags: ['проекты', 'новости']
draft: false
summary: ''
---
![Поисковик курсов Athena](/static/images/blog/projects/athena.png)

## Инфоцигане и как с ними бороться

Наверно каждый из вас встречал рекламу где какая-то компания обещает что вы купите у них уникальнейший курс за 80 тыс. рублей и просто не можете не стать разработчиком. Какой у них настолько успешный курс, которых нет ни у кого на рынке. Вот ты главное оплати за курс и ты и отучишься и еще на работу пойдешь. Все это - Инфоцыганство.

![Лапша на уши](/static/images/blog/projects/lapsha.jpg)

Как на примере опыта в [Яндекс Практикуме](https://habr.com/ru/post/592821/), многие оставались недовольными курсами и [требовали возврат средств](https://tutortop.ru/school-reviews/yandex_praktikum/), на выпускников которой сама компания [не возлагает надежд](https://vc.ru/hr/337331-ty-kto-takoy-pochemu-yandeks-praktikum-ne-verit-v-sobstvennyh-vypusknikov).

Отчасти чтобы бороться с инфоцыганами я и создал данный поисковик. Данный проект был создан для быстрого и удобного поиска курсов и контента на многих языках. С помощью нее вы можете найти бесплатные и платные курсы, благодаря которым вы можете сопоставить реальную цену курсов которые предлагают люди.

## Как я создавал парсер курсов
На бумаге, создание парсера не состовляло труда. Нужно было лишь обдумать что именно будет собирать парсер и начать создавать отдельно каждого бота под конкретный сайт. Однако, чем дальше я работал тем больше я понимал, насколько больше дел мне нужно сделать:
1. Нужно создать 10 парсеров вебсайтов, и каждый из них работает уникально и нельзя просто взять и копипастить код со старого парсера. Некоторые сайты были настолько просты, что хватало и одного быстрого запроса. Другие же, требуют асинхронного парсера которому нужно сделать 20,000 запросов когда он может делать лишь 100 запросов на сервер за раз. Некоторые сайты буквально ломаются когда я делаю больше чем 3 запроса и нужно искуственно замедлять скоро парсинга, иначе сайт попросту сломается. И это только 3 вебсайта.
2. Нужно куда-то собирать эти данные. Обдумываение структуры Базы Данных была сплошная боль через метод проб и ошибок, но это лишь пол дела. Нужно также полученные данные анализировать, фильтровать и сортировать, и каждый парсер также требует инидивидуальной работы.
3. После сбора данных, нужно создать для него веб-сервис с удобным API, чтобы фронтенд мог им пользоваться. Нужно поднять сервер на Python чтобы он всегда был готов отвечать на запросы.
4. Чтобы люди могли им пользоваться, нужно создать красивый и удобный дизайн. Я сделал его на коленках и бубном, что и сказывается на его дизайне.

Ссылка на проект: https://athena.op-onai.kz
